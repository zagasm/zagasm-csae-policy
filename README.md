Child Safety Standards & CSAE Prevention Policy



Last Updated: June 23, 2025

At Zagasm, we are deeply committed to the safety and well-being of all users, especially minors. This document outlines our publicly accessible child safety standards and our policies to combat Child Sexual Abuse and Exploitation (CSAE). Our approach is rooted in transparency, responsibility, and user empowerment.






ğŸ”’ 1. Commitment to Child Safety and CSAE Prevention
We prohibit any form of content, behavior, or user activity that promotes or depicts child sexual abuse, exploitation, grooming, or inappropriate interactions with minors.


We enforce a zero-tolerance policy on CSAE content and related behaviors.


We actively monitor, detect, and report any suspected CSAE to relevant legal authorities and child protection organizations.






ğŸ§­ 2. Content Moderation and Detection Procedures
To prevent abuse and maintain a safe platform:
We use automated content filtering systems to detect inappropriate messages, media, and behavior.


We employ manual moderation by trained safety personnel to review flagged content.


All images and videos are scanned against known CSAE content databases (e.g., PhotoDNA, Project Arachnid).


Our system monitors and limits interactions involving users who self-identify or appear to be under 18.






ğŸ“¢ 3. User Reporting and Escalation
Users can easily report violations through multiple channels:
In-app report and block buttons are available on all user profiles and chat interfaces.


Reports are prioritized and reviewed within 24 hours.


Serious reports involving child safety are escalated immediately to our Safety Response Team and may be reported to:


National Center for Missing & Exploited Children (NCMEC)


Local law enforcement


If you believe a child is in danger or you encounter CSAE content, please report it immediately at:
 ğŸ“§ safety@zagasm.com


 



ğŸ›¡ï¸ 4. User Safety Features
We have implemented multiple tools to protect users:
Profile verification: Optional photo-based verification to reduce impersonation.


Age restriction: Users must confirm their age during onboarding; accounts suspected to belong to minors in adult contexts are restricted or removed.


Auto-blocking: Repeatedly reported accounts are automatically blocked pending review.


Chat restrictions: New users have limited communication abilities until trust signals are verified.


Suspicious behavior detection: AI-based alerts flag grooming-like behavior for review.







ğŸ“œ 5. Community Guidelines & Enforcement
All users agree to abide by our Community Guidelines, which strictly prohibit:
Any sexual or suggestive content involving minors.


Inappropriate communication with minors.


Sharing of CSAE-related content or links.


Solicitation or grooming behavior.


Violations result in immediate account suspension or permanent ban, and evidence may be shared with law enforcement.
Read our full Community Guidelines.






ğŸ“¬ 6. Contact and Accountability
We maintain an open and transparent safety policy. For concerns, press, or escalations:
ğŸ“§ safety@zagasm.com


ğŸ“  ğŸ“§ +234 802 818 0778 (for urgent safety matters)


ğŸ“ Office: Opposite Konwea Plaza, Asaba Delta State, Nigeria


ğŸ§© 7. Policy Updates
This policy may be updated periodically to meet evolving safety standards and compliance requirements. Significant changes will be announced on our website.

